<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Lei Sun" />

<meta name="date" content="2017-03-11" />

<title>Bernoulli-Gaussian &amp; Normal Means</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">BayeS</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/LSun/BayeS">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Bernoulli-Gaussian &amp; Normal Means</h1>
<h4 class="author"><em>Lei Sun</em></h4>
<h4 class="date"><em>2017-03-11</em></h4>

</div>


<p><strong>Last updated:</strong> 2017-03-12</p>
<p><strong>Code version:</strong> 8c206a4</p>
<div id="problem" class="section level2">
<h2>Problem</h2>
<p>In normal means problem, suppose</p>
<p><span class="math display">\[
\begin{array}{c}
z|\mu \sim N(\mu, s^2)\\
\mu \sim g
\end{array}
\]</span></p>
<p>Under Bayesian framework, we get an estimator <span class="math inline">\(\hat\mu_B\)</span> from the posterior distribution <span class="math inline">\(\mu | z\)</span>, optimal to a pre-specified loss function.</p>
<p>In particular, the best estimator in terms of quadratic loss is <span class="math inline">\(E[\mu | z]\)</span>, the posterior mean. By Tweedie’s formula</p>
<p><span class="math display">\[
E[\mu | z] = z + s^2\nabla\log f(z)
\]</span> where <span class="math inline">\(f\)</span> is the marginal probability density of <span class="math inline">\(z\)</span>, after integrating out <span class="math inline">\(\mu\)</span>. <span class="math inline">\(f\)</span> is usually a convolution of prior and likelihood. In the normal means setting, <span class="math inline">\(f = N(0, s^2) * g\)</span>.</p>
<p><strong>The problem is whether we can find a <span class="math inline">\(\phi\)</span>, such that the optimal Bayesian estimator <span class="math inline">\(\hat\mu_B\)</span> is a solution to the regularized least squares with <span class="math inline">\(\phi\)</span> as the penalty.</strong></p>
<p><span class="math display">\[
\hat\mu_B = \arg\min_u\{\frac1{2s^2}(z - u)^2 + \phi(u)\} = \text{prox}_{s^2\phi}(z)
\]</span></p>
<div id="posterior-mean-and-regularized-least-squares" class="section level3">
<h3>Posterior mean and regularized least squares</h3>
<p>If we let <span class="math inline">\(\hat\mu_B\)</span> be the posterior mean <span class="math inline">\(E[\mu | z]\)</span>, we are essentially matching Tweedie’s formula with a proximal operator, such that</p>
<p><span class="math display">\[
z + s^2\nabla\log f(z) = \text{prox}_{s^2\phi}(z)
\]</span> For clarity let <span class="math inline">\(u := \text{prox}_{s^2\phi}(z)\)</span>. Now we are using two key properties of a proximal operator.</p>
<p><span class="math display">\[
u = \text{prox}_{\lambda f}(z) \Rightarrow
\begin{array}{l}
u \in z - \lambda\partial f(u) \\
u = z - \lambda\nabla M_{\lambda f}(z)
\end{array}
\]</span></p>
<p>By the properties of the proximal operator we have</p>
<p><span class="math display">\[
z - u \in s^2\partial\phi(u)
\]</span> where <span class="math inline">\(\partial\phi\)</span> is the (local) subgradient of <span class="math inline">\(\phi\)</span>. Putting together the previous two equations</p>
<p><span class="math display">\[
\begin{array}{c}
-s^2\nabla\log f(z) \in s^2\partial\phi(u)\\
u = \text{prox}_{s^2\phi}(z)
\end{array}
\]</span></p>
<p>We can write it in another way, and use the property of the proximal operator one more time</p>
<p><span class="math display">\[
z \in (z - s^2\partial\phi(u)) - s^2\nabla\log f(z) \Rightarrow z \in \text{prox}_{s^2\log f}(z - s^2\partial\phi(u)))
\]</span> Combine this with</p>
<p><span class="math display">\[
u \in z - s^2\partial\phi(u)
\]</span> use the property of the proximal operator, and we get</p>
<p><span class="math display">\[
z = \text{prox}_{s^2\log f}(u) = u - s^2\nabla M_{s^2\log f}(u)
\]</span></p>
<p>Now we have</p>
<p><span class="math display">\[
\begin{array}{l}
z = u - s^2\nabla M_{s^2\log f}(u)\\
z  \in u + s^2\partial\phi(u)
\end{array}
\]</span></p>
<p>Compare this two, we can write</p>
<p><span class="math display">\[
- \nabla M_{s^2\log f}(u) \in \partial\phi(u)
\]</span></p>
<p>One such <span class="math inline">\(\phi\)</span> can be written as</p>
<p><span class="math display">\[
\phi = -M_{s^2\log f} + c
\]</span></p>
<p>We’ve obtained that</p>
<p><span class="math display">\[
z = \text{prox}_{s^2\log f}(u)
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\phi(u) = -M_{s^2\log f}(u) + c = -\{\log f(z) + \frac{1}{2s^2}(z - u)^2\} + c
\]</span> where <span class="math display">\[
\begin{array}{rl}
&amp; z = \text{prox}_{s^2\log f}(u) \\
\Rightarrow &amp; u = z + s^2\log f(z) = E[\mu | z]
\end{array}
\]</span> and <span class="math inline">\(c\)</span> is a constant to make sure that <span class="math inline">\(\phi(0) = 0\)</span>.</p>
<p>So in the normal means problem, or in other words, we have a normal likelihood with known noise level <span class="math inline">\(s^2\)</span> and a prior <span class="math inline">\(g\)</span> for the unknown mean <span class="math inline">\(\mu\)</span>, and we use the posterior mean as the estimate, we can obtain <span class="math inline">\(\phi\)</span> in the following steps.</p>
<ol style="list-style-type: decimal">
<li><p>Figure out the posterior mean <span class="math inline">\(E[\mu|z]\)</span> for a given observation <span class="math inline">\(z\)</span>, for example, by Tweedie’s formula.</p></li>
<li><p>For each <span class="math inline">\(u\)</span>, find a <span class="math inline">\(z\)</span> such that <span class="math inline">\(E[\mu|z] = u\)</span>.</p></li>
<li><p><span class="math inline">\(\phi(u) = -\{\log f(z) + \frac{1}{2s^2}(z - u)^2\}\)</span>.</p></li>
<li><p>To make sure <span class="math inline">\(\phi(0) = 0\)</span>, <span class="math inline">\(\phi(u) \leftarrow \phi(u) - \phi(0)\)</span>.</p></li>
</ol>
<p>Then</p>
<p><span class="math display">\[
E[\mu|z] = \arg\min_u \frac{1}{2s^2}(z - u)^2 + \phi(u)
\]</span></p>
</div>
</div>
<div id="bernoulli-gaussian-spike-and-slab" class="section level2">
<h2>Bernoulli-Gaussian (spike-and-slab)</h2>
<p>The Bernoulli-Gaussian framework specifies the prior on <span class="math inline">\(\mu\)</span> as</p>
<p><span class="math display">\[
\begin{array}{rl}
&amp; g(\mu) = \pi\delta_0 + (1 - \pi)N(\mu; 0, \sigma^2)\\
\Rightarrow &amp; f(z) = \pi N(z; 0, s^2) + (1 - \pi)N(z; 0, \sigma^2 + s^2)
\end{array}
\]</span> where <span class="math inline">\(\delta_0\)</span> is a point mass at 0, and <span class="math inline">\(N(\mu; 0, \sigma^2)\)</span> is the density of <span class="math inline">\(N(0, \sigma^2)\)</span> at <span class="math inline">\(\mu\)</span>, calculated in <code>R</code> as <code>dnorm(mu, 0, sigma)</code>.</p>
<p>Luckily for Bernoulli-Gaussian, the posterior distribution for <span class="math inline">\(\mu | z\)</span> can be written out analytically.</p>
<p><span class="math display">\[
\begin{array}{c}
\mu | z \sim p\delta_0 + (1 - p)N(\frac{z\sigma^2}{\sigma^2 + s^2}, \frac{\sigma^2s^2}{\sigma^2 + s^2})\\
p = \frac{\pi N(z; 0, s^2)}{\pi N(z; 0, s^2) + (1 - \pi)N(z; 0, \sigma^2 + s^2)}
\end{array}
\]</span></p>
<div id="posterior-mean" class="section level3">
<h3>Posterior mean</h3>
<p>Therefore, the posterior mean</p>
<p><span class="math display">\[
E[\mu | z] = (1 - p) \frac{z\sigma^2}{\sigma^2 + s^2} = \frac{z\sigma^2}{\sigma^2 + s^2 } \frac{(1 - \pi)N(z; 0, \sigma^2 + s^2)}{\pi N(z; 0, s^2) + (1 - \pi) N(z; 0, \sigma^2 + s^2)}
\]</span></p>
<pre class="r"><code>pm = function(z, s, sigma, pi) {
    p1 = pi * dnorm(z, 0, s)
    p2 = (1 - pi) * dnorm(z, 0, sqrt(s^2 + sigma^2))
    p1 = p1 / (p1 + p2)
    p2 = 1 - p1
    pm = z * sigma^2 / (sigma^2 + s^2) * p2
    return(pm)
}

z = seq(-6, 6, 0.01)
s = 1
pi = 0.9
pm1 = pm(z, s, 1, pi)
pm2 = pm(z, s, 10, pi)
pm3 = pm(z, s, 100, pi)
plot(z, pm2, type = &quot;l&quot;, xlab = &quot;Observation z&quot;, ylab = &quot;Posterior Mean&quot;,
     col = &quot;blue&quot;, main = bquote(paste(&quot;Bernoulli-Gaussian shrinkage with&quot;, ~pi == .(pi), &quot;,&quot;, ~s == .(s)))
     )
lines(z, pm1, col = &quot;black&quot;)
abline(0, 1, lty = 2, col = &quot;green&quot;)
abline(h = 0, lty = 2, col = &quot;yellow&quot;)
lines(z, pm3, col = &quot;red&quot;)
legend(&quot;topleft&quot;, col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;), lty = 1, c(expression(sigma == 1), expression(sigma == 10), expression(sigma == 100)))</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-1-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Note that the posterior mean is never strictly zero unless <span class="math inline">\(z = 0\)</span>, yet as <span class="math inline">\(\sigma\to\infty\)</span>, it behaves more and more like hard-thresholding.</p>
</div>
<div id="imposing-sparsity" class="section level3">
<h3>Imposing sparsity</h3>
<p>In spike-and-slab framework, the posterior distribution of <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[
\mu | z \sim p\delta_0 + (1 - p)N(\frac{z\sigma^2}{\sigma^2 + s^2}, \frac{\sigma^2s^2}{\sigma^2 + s^2})
\]</span> Thus it’s also a mixture of a point mass at <span class="math inline">\(0\)</span> and a normal. Using the posterior mean <span class="math inline">\(E[\mu|z]\)</span> directly as the estimate <span class="math inline">\(\hat\mu_B\)</span>, the estimate is never strictly <span class="math inline">\(0\)</span> unless <span class="math inline">\(z = 0\)</span>. Instead, in order to impose sparsity, we usually set <span class="math inline">\(\hat\mu_B = 0\)</span> if <span class="math inline">\(p \geq 0.5\)</span>. Meanwhile, when <span class="math inline">\(p &lt; 0.5\)</span>, we assume <span class="math inline">\(\mu | z\)</span> is not from a point mass at <span class="math inline">\(0\)</span> but from the other component of the mixture <span class="math inline">\(N(\frac{z\sigma^2}{\sigma^2 + s^2}, \frac{\sigma^2s^2}{\sigma^2 + s^2})\)</span>, hence set <span class="math inline">\(\hat\mu_B\)</span> to its mean <span class="math inline">\(\frac{z\sigma^2}{\sigma^2 + s^2}\)</span>.</p>
<p>that is</p>
<p><span class="math display">\[
\begin{array}{rl}
&amp; \pi N(z; 0, s^2) \geq (1 - \pi)N(z; 0, \sigma^2 + s^2) \\
\Leftrightarrow &amp;
\frac{N(z; 0, \sigma^2 + s^2)}{N(z; 0, s^2)} \leq \frac{\pi}{1 - \pi}\\
\Leftrightarrow &amp;
|z| \leq \sqrt{2(\sigma^2 + s^2)(s^2 / \sigma^2)\log((\frac{\pi}{1 - \pi})\sqrt{(\sigma^2 + s^2)/ s^2})} := z_{s, \pi, \sigma}^*
\end{array}
\]</span> Here we can use a simple rule</p>
<p><span class="math display">\[
\hat\mu_B = 
\begin{cases}
0 &amp; |z| \leq z_{s, \pi, \sigma}^* \\
\frac{z\sigma^2}{\sigma^2 + s^2} &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>as <span class="math inline">\(\sigma \to \infty\)</span>, it is very close to hard-thresholding.</p>
<pre class="r"><code>s = 1
pi = 0.9
sigma = 100
zstar = sqrt(2 * (sigma^2 + s^2) * (s^2 / sigma^2) * log(pi / (1 - pi) * sqrt((sigma^2 + s^2) / s^2)))

pdf1 = dnorm(z, 0, s)
pdf2 = dnorm(z, 0, sqrt(sigma^2 + s^2))
plot(z, pdf1, type = &quot;l&quot;, xlab = &quot;observation&quot;, ylab = &quot;Probability Density Function&quot;,
     main = bquote(paste(s == .(s),&quot;, &quot;, pi == .(pi),&quot;, &quot;, sigma == .(sigma)))
       )
lines(z, pdf2, col = &quot;red&quot;)
segments(zstar, -1, zstar, 2 * dnorm(zstar, 0, sqrt(sigma^2 + s^2)), lty = 1, col = &quot;blue&quot;)
legend(&quot;topright&quot;, col = c(&quot;black&quot;, &quot;red&quot;), c(expression(N(0, s^2)), expression(N(0, sigma^2 + s^2))), lty = 1)
text(zstar, 2 * dnorm(zstar, 0, sqrt(sigma^2 + s^2)), label = expression(z^&quot;*&quot;), pos = 3)</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>x = seq(zstar, 6, 0.01)
y = x * sigma^2 / (sigma^2 + s^2)
plot(x, y, type = &quot;n&quot;, xlim = c(-max(x), max(x)), ylim = c(-max(y), max(y)), xlab = &quot;observation&quot;, ylab = expression(hat(mu)),
     main = bquote(paste(s == .(s),&quot;, &quot;, pi == .(pi),&quot;, &quot;, sigma == .(sigma))))
abline(h = 0, lty = 2, col = &quot;yellow&quot;)
abline(0, 1, lty = 2, col = &quot;green&quot;)
lines(x, y)
x = -seq(zstar, 6, 0.01)
y = x * sigma^2 / (sigma^2 + s^2)
lines(x, y)
segments(-zstar, 0, zstar, 0)
segments(-zstar, 0, -zstar, -zstar * sigma^2 / (sigma^2 + s^2), lty = 3)
segments(zstar, 0, zstar, zstar * sigma^2 / (sigma^2 + s^2), lty = 3)</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="comparison" class="section level3">
<h3>Comparison</h3>
<pre class="r"><code>plot(z, pm2, type = &quot;n&quot;, xlab = &quot;Observation z&quot;, ylab = &quot;Posterior Mean&quot;,
     col = &quot;blue&quot;, main = bquote(paste(&quot;Bernoulli-Gaussian shrinkage with&quot;, ~pi == .(pi), &quot;,&quot;, ~s == .(s)))
     )
abline(0, 1, lty = 2, col = &quot;green&quot;)
abline(h = 0, lty = 2, col = &quot;yellow&quot;)
lines(z, pm2, col = &quot;blue&quot;)
lines(z, pm1, col = &quot;black&quot;)
lines(z, pm3, col = &quot;red&quot;)
x = seq(zstar, 6, 0.01)
y = x * sigma^2 / (sigma^2 + s^2)
col = &quot;purple&quot;
lines(x, y, col = col)
x = -seq(zstar, 6, 0.01)
y = x * sigma^2 / (sigma^2 + s^2)
lines(x, y, col = col)
segments(-zstar, 0, zstar, 0, col = col)
segments(-zstar, 0, -zstar, -zstar * sigma^2 / (sigma^2 + s^2), lty = 3, col = col)
segments(zstar, 0, zstar, zstar * sigma^2 / (sigma^2 + s^2), lty = 3, col = col)
legend(&quot;topleft&quot;, col = c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;, col), lty = 1, c(expression(sigma == 1), expression(sigma == 10), expression(sigma == 100), expression(paste(sigma == 100, &quot;, sparsity&quot;))))</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="bernoulli-gaussian-as-regularized-least-squares" class="section level2">
<h2>Bernoulli-Gaussian as regularized least squares</h2>
<p>Under the model</p>
<p><span class="math display">\[
\begin{array}{c}
z|\mu \sim N(\mu, s^2)\\
\mu \sim g = \pi\delta_0 + (1 - \pi)N(0, \sigma^2)
\end{array}
\]</span></p>
<p>The key question is to find <span class="math inline">\(\phi\)</span> such that <span class="math inline">\(\hat\mu_B = \text{prox}_{s^2\phi}(z)\)</span>.</p>
<div id="posterior-mean-1" class="section level3">
<h3>Posterior mean</h3>
<p><span class="math display">\[
\hat\mu_B = E[\mu|z] = \frac{z\sigma^2}{\sigma^2 + s^2 } \frac{(1 - \pi)N(z; 0, \sigma^2 + s^2)}{\pi N(z; 0, s^2) + (1 - \pi) N(z; 0, \sigma^2 + s^2)}
\]</span></p>
<p>Thus <span class="math inline">\(\phi\)</span> can be generated in following steps.</p>
<ol style="list-style-type: decimal">
<li><p>For each <span class="math inline">\(u\)</span>, find a <span class="math inline">\(z\)</span> such that <span class="math inline">\(E[\mu|z] = u\)</span>, using aforementioned formula for <span class="math inline">\(E[\mu|z]\)</span>.</p></li>
<li><p>Compute <span class="math inline">\(f(z) = \pi N(z; 0, s^2) + (1 - \pi)N(z; 0, \sigma^2 + s^2)\)</span>, and specifically, <span class="math inline">\(f(0) = \pi N(0; 0, s^2) + (1 - \pi)N(0; 0, \sigma^2 + s^2)\)</span>.</p></li>
<li><p><span class="math inline">\(\phi(u) = -\{\log f(z) + \frac{1}{2s^2}(z - u)^2\} + \log f(0)\)</span></p></li>
</ol>
<pre class="r"><code>phi = function (u, s, sigma, pi) {
  zhat = c()
  for (i in 1:length(u)) {
    pmu = function(z) {
      pmu = pm(z, s, sigma, pi) - u[i]
      return(pmu)
    }
    zhat[i] = uniroot(pmu, c(-20, 20))$root
  }
  fz = pi * dnorm(zhat, 0, s) + (1 - pi) * dnorm(zhat, 0, sqrt(s^2 + sigma^2))
  fz0 = pi * dnorm(0, 0, s) + (1 - pi) * dnorm(0, 0, sqrt(s^2 + sigma^2))
  phi_sigma = -log(fz) - (zhat - u)^2 / (2 * s^2) + log(fz0)
  return(phi_sigma)
}

s = 1
pi = 0.9
u = seq(-6, 6, 0.01)
ymax = max(phi(u, s, sigma = 1, pi))
plot(u, phi(u, s, sigma = 1, pi), type = &quot;n&quot;, ylim = c(0, ymax),
     xlab = expression(u), ylab = expression(phi(u)),
     main = bquote(paste(~pi == .(pi), &quot;,&quot;, ~s == .(s)))
     )
nsigma = c(1, 2, 5, 10, 100)
k = 1
for (sigma in nsigma) {
  lines(u, phi(u, s, sigma = sigma, pi), col = rainbow(length(nsigma))[k])
  k = k + 1
}
legend(&quot;top&quot;, col = rainbow(length(nsigma))[1:(k - 1)], lty = 1,
       legend = expression(
         sigma == 1,
         sigma == 2,
         sigma == 5,
         sigma == 10,
         sigma == 100
       )
       )</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="imposing-sparsity-1" class="section level3">
<h3>Imposing sparsity</h3>
<p>As discussed before, in order to impose sparsity in <span class="math inline">\(\hat\mu_B\)</span>, we adopt the rule</p>
<p><span class="math display">\[
\hat\mu_B = 
\begin{cases}
0 &amp; |z| \leq z_{s, \pi, \sigma}^* \\
\frac{z\sigma^2}{\sigma^2 + s^2} &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>It’s easy to see that the penalty term corresponding to this rule should be a <span class="math inline">\(l_2\)</span>-<span class="math inline">\(l_0\)</span> regularization. In particular,</p>
<p><span class="math display">\[
\phi(u) = \frac{1}{2\sigma^2}u^2 + \lambda\|u\|_0
\]</span> where <span class="math inline">\(\|u\|_0 = I(u \neq 0)\)</span> is the indicator of <span class="math inline">\(u\)</span> being nonzero. A little algebra shows that</p>
<p><span class="math display">\[
\lambda = \frac{{z^*}^2\sigma^2}{2s^2(\sigma^2 + s^2)} = \log\left(\frac{\pi}{1-\pi}\sqrt{\frac{\sigma^2 + s^2}{s^2}}\right)
\]</span> Written in another way</p>
<p><span class="math display">\[
\begin{array}{rl}
&amp; \arg\min_u\{\frac1{2s^2}(z - u)^2 + \phi(u)\}\\
= &amp; \arg\min_u\{\frac1{2s^2}(z - u)^2 + \frac{1}{2\sigma^2}u^2 + \log\left(\frac{\pi}{1-\pi}\sqrt{\frac{\sigma^2 + s^2}{s^2}}\right)\|u\|_0\}\\
= &amp;
\begin{cases}
0 &amp; |z| \leq z_{s, \pi, \sigma}^* \\
\frac{z\sigma^2}{\sigma^2 + s^2} &amp; \text{otherwise}
\end{cases}
\end{array}
\]</span></p>
<pre class="r"><code># zstar = function (s, pi, sigma) {zstar = sqrt(2 * (sigma^2 + s^2) * (s^2 / sigma^2) * log(pi / (1 - pi) * sqrt((sigma^2 + s^2) / s^2))); return(zstar)}
s = 1
pi = 0.9
# phi_s = function (u, s, pi, sigma) {phi_s = 1 / (2 * sigma^2) * u^2 + zstar(s, pi, sigma = 1) * (s^2 + sigma^2) / (2 * sigma^2 * s^2); return(phi_s)}

phi_s = function (u, s, pi, sigma) {phi_s = 1 / (2 * sigma^2) * u^2 + log(pi / (1 - pi) * sqrt((sigma^2 + s^2) / s^2)); return(phi_s)}
ymax = max(phi_s(u, s, pi, sigma = 1))
plot(u, phi_s(u, s, pi, sigma = 1), type = &quot;n&quot;, ylim = c(0, ymax),
     xlab = expression(u), ylab = expression(phi(u)),
     main = bquote(paste(~pi == .(pi), &quot;,&quot;, ~s == .(s)))
     )
nsigma = c(1, 2, 5, 10, 100)
k = 1
for (sigma in nsigma) {
  lines(u, phi_s(u, s, pi, sigma = sigma), col = rainbow(length(nsigma))[k])
  points(0, phi_s(0, s, pi, sigma = sigma), col = rainbow(length(nsigma))[k])
  points(0, 0, col = rainbow(length(nsigma))[k], pch = 19)
  segments(0, 0, 0, phi_s(0, s, pi, sigma = sigma), lty = 3, col = rainbow(length(nsigma))[k])
  k = k + 1
}
legend(&quot;top&quot;, col = rainbow(length(nsigma))[1:(k - 1)], lty = 1,
       legend = expression(
         sigma == 1,
         sigma == 2,
         sigma == 5,
         sigma == 10,
         sigma == 100
       )
       )</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="comparison-1" class="section level3">
<h3>Comparison</h3>
<pre class="r"><code>u = seq(-6, 6, 0.01)
ymax = max(c(phi(u, s, sigma = 1, pi), phi_s(u, s, pi, sigma = 1)))
plot(u, phi(u, s, sigma = 1, pi), type = &quot;n&quot;, ylim = c(0, ymax),
     xlab = expression(u), ylab = expression(phi(u)),
     main = bquote(paste(~pi == .(pi), &quot;,&quot;, ~s == .(s)))
     )
nsigma = c(1, 2, 5, 10, 100)
k = 1
for (sigma in nsigma) {
  lines(u, phi(u, s, sigma = sigma, pi), col = rainbow(length(nsigma))[k])
  lines(u, phi_s(u, s, pi, sigma = sigma), col = rainbow(length(nsigma))[k], lty = 2)
  points(0, phi_s(0, s, pi, sigma = sigma), col = rainbow(length(nsigma))[k])
  points(0, 0, col = rainbow(length(nsigma))[k], pch = 19)
  segments(0, 0, 0, phi_s(0, s, pi, sigma = sigma), lty = 3, col = rainbow(length(nsigma))[k])
  k = k + 1
}
legend(&quot;top&quot;,
       col = c(rainbow(length(nsigma))[1:(k - 1)], 6),
       lty = c(rep(1, length(nsigma)), 2),
       legend = c(expression(
         sigma == 1,
         sigma == 2,
         sigma == 5,
         sigma == 10,
         sigma == 100
       ), &quot;sparsity&quot;)
       )</code></pre>
<p><img src="figure/bernoulli-gaussian.Rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="session-information" class="section level2">
<h2>Session Information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] backports_1.0.5 magrittr_1.5    rprojroot_1.2   tools_3.3.2    
 [5] htmltools_0.3.5 yaml_2.1.14     Rcpp_0.12.9     stringi_1.1.2  
 [9] rmarkdown_1.3   knitr_1.15.1    git2r_0.18.0    stringr_1.2.0  
[13] digest_0.6.11   workflowr_0.4.0 evaluate_0.10  </code></pre>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
