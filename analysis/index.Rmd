---
title: "Bayesian Shrinkage, Selection, Sparsity"
output:
  html_document:
    toc: false
---

Working with [Matthew Stephens] and [Nicholas Polson], I'm exploring various ideas in statistical shrinkage, selection, and sparsity, especially in Bayesian framework.

*  [Bernoulli-Gaussian spike-and-slab applied to normal means](bernoulli-gaussian.html)
*  [Bernoulli-Laplace spike-and-slab applied to normal means](bernoulli-laplace.html)

The problem is whether we can find a $\phi$, such that $\hat\mu_B$, the optimal Bayesian estimator to a certain loss, is a solution to the regularized least squares with $\phi$ as the penalty.  This framework of matching Tweedie's formula to a proximal operator can potentially be generalized to the exponential family likelihood, not just normal means.  The specific formula should be changed accordingly.


[Matthew Stephens]: http://stephenslab.uchicago.edu/
[Nicholas Polson]: http://faculty.chicagobooth.edu/nicholas.polson/
